{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "contemporary-holiday",
   "metadata": {},
   "source": [
    "# Land Use Categorization for TMD23\n",
    "This is intended to be a demo implementing the new definitions of land use categorizations for the Trip Generation step of the TDM23 (travel demand model in development). This notebook starts with categorization of Central Business Districts (CBDs).\n",
    "\n",
    "\n",
    "Started March 30th, 2021 - Margaret Atkinson\n",
    "\n",
    "#### Requirements:\n",
    "This is running as a ipynb in Jupyter Notebooks in an Anaconda environment that contains the following:\n",
    "- Python 3.7\n",
    "- numpy\n",
    "- pandas\n",
    "- openmatrix\n",
    "- matplotlib\n",
    "- descartes\n",
    "- ipympl\n",
    "- geopandas\n",
    "- nb_conda\n",
    "- nb_conda_kernels\n",
    "- folium\n",
    "- branca\n",
    "- jenkspy (INSTALL FIRST)\n",
    "\n",
    "For more information on how this environment was set up, see: https://github.com/bkrepp-ctps/mde-prototype-python\n",
    "\n",
    "#### Just a note about environments:\n",
    "\n",
    "This script seems to require pyproj > 2.2. The environment base_py_37_branca seems to have this.\n",
    "\n",
    "Hypothesis: In order for pyproj to deal with CRS (coordinate reference systems) in the geodataframes - we need to be using the most recent version of pyproj. See: https://geopandas.org/docs/user_guide/projections.html#upgrading-to-geopandas-0-7-with-pyproj-2-2-and-proj-6\n",
    "\n",
    "This changes how we specify CRSs. Also note that going from pivot table back to geodataframe (even though the pivot table has geometry) we need to specify the CRS - which should be the same CRS that the data came out of.\n",
    "\n",
    "Using a version of pyproj that uses the {'init': 'ESPG4326'} format is giving me inconsistent results - sometimes maintaining the CRS and sometimes not. This causes the buffers to be larger than desired and causes problems for spatial join.\n",
    "\n",
    "\n",
    "#### Links about Decay Functions\n",
    "- https://aceso.readthedocs.io/_/downloads/en/latest/pdf/\n",
    "- https://geographicdata.science/book/notebooks/04_spatial_weights.html\n",
    "- https://github.com/pysal/pysal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-gathering",
   "metadata": {},
   "source": [
    "## Definitions:\n",
    "Higher classes are exclusions for lower classes (e.g. if TAZ is both CBD and Dense Urban, it will only be CBD).\n",
    "### CBD\n",
    "CBD: A TAZ is marked as a CBD if it has Urban density AND if it is within 0.5 miles of two heavy rail (subway) stops from two different lines or within  0.25 miles of a green line stop that serves all four branches.\n",
    "\n",
    "Methodology Plan: Buffer each heavy rail stop and dissolve by line to get one buffer per heavy rail line and one buffer for the green line (light rail) for the four stops that serve all four branches of the green line.. \n",
    " - Method 2: Intersect heavy rail buffers (and 4 light rail buffers) to get polygons where buffers overlap each other. Dissolve those polygons into one polygon. If dissolved buffer polygon covers over 50% of the TAZ and the TAZ has Urban Density, it is a CBD.\n",
    "\n",
    "\n",
    "Data: (shapefiles)\n",
    "- TAZ's (polygons)\n",
    "- Heavy Rail Stops with Line field (points)\n",
    "- Light Rail Stops with Line field (points)\n",
    "\n",
    "Notes:\n",
    "- Additional filter: \n",
    "    - The TAZ must be over 50% covered by the overlap of two heavy rail stop buffers of different lines (like red/orange)\n",
    "\n",
    "### Dense Urban\n",
    "#### Basic Definition:\n",
    "\n",
    "OLD:\n",
    "(0.5 mile buffer for heavy rail stops) OR (0.5 mile buffer for CR stops AND Urban density of landuse) OR (0.5 mile buffer for 5 mins headway overlapping bus routes AND Urban density of model landuse)\n",
    "\n",
    "- *headway is frequency - buses must run every 5 minutes in the AM model period*\n",
    "- we will be using the combined headway procedure from the model for nodes where the headway 5 min or less means that there are 36 buses or more per 3 hours (AM time period). These nodes will be buffered to meet the criteria for overlapping bus routes (but the buffers need not overlap).\n",
    "\n",
    "NEW: \n",
    "(0.5 mile buffer for heavy rail stops) OR (0.5 mile buffer for CR stops AND Urban density of landuse) OR (0.5 mile buffer for all nodes that have a frequency >= 36 during the AM Peak Period AND Urban density of model landuse)\n",
    "\n",
    "#### GIS Definition:\n",
    "\n",
    "A TAZ is defined as Dense Urban if the TAZ does not meet the criteria for a CBD and meets one of the follow criteria:\n",
    "1. TAZ must intersect with a 0.5 mile buffer for heavy rail stops OR \n",
    "2. (a TAZ must intersect with a 0.5 mile buffer for CR stops AND meet the landuse density threshold for Urban density) OR \n",
    "3. (a TAZ must intersect with a 0.5 mile buffer for a node that has a frequency >= 36 during the AM Peak Period in the model AND the TAZ must meet the landuse density threshold for Urban density)\n",
    "\n",
    "#### Density (calculated at the TAZ level):\n",
    "\n",
    "Density = (Population + Employment)/Area in Sq Mi\n",
    "- [1] Urban density range is 10,000 - 3,805,119 ;  \n",
    "- [2] Suburban density range is 5,000 - 9,999 ;  \n",
    "- [3] Rural density is 0 - 4,999 ; \n",
    "- Boston Core includes TAZs 1-155 (we don't need this usually urban density, will fall in Urban density)\n",
    "\n",
    "#### Notes: \n",
    "- Excludes CBD\n",
    "- No overlapping heavy rail stops\n",
    "- the 5 min node frequency file is MBTA only, the 15 min node frequency file is all bus routes in the state (private buses, RTAs, etc.).\n",
    "\n",
    "#### Data:\n",
    "- Heavy rail stops (points) = Blue, Orange, Red lines (including Mattapan which counts as Red)\n",
    "- Commute Rail stops (points)\n",
    "- TAZs with population and employment (polygons)\n",
    "- Bus routes with AM headway (5 minutes) \n",
    "    - (lines) = Modes 1, 2, 3, use AM_Headway <= 5\n",
    "    - only MBTA\n",
    "\n",
    "\n",
    "### Fringe Urban\n",
    "(1  mile buffer for heavy rail stops) OR (0.5 mile buffer for light rail stops) OR (0.5 mile buffer for all nodes that have a frequency >= 36 during the AM Peak Period in the model AND Suburban density) OR (0.5 mile buffer for CR stops AND Suburban density of model  landuse)\n",
    "\n",
    "***Green line and Silver line are light rail (multiple modes, use them all) \n",
    "\n",
    "\n",
    "#### GIS Definition:\n",
    "\n",
    "A TAZ is defined as Fringe Urban if the TAZ does not meet the criteria for a CBD or Dense Urban and meets one of the follow criteria:\n",
    "1. TAZ must intersect with a 1 mile buffer for heavy rail stops OR \n",
    "2. (TAZ must intersect with a 0.5 mile buffer for light rail stops) OR\n",
    "3. (a TAZ must intersect with a TAZ must intersect with a 0.5 mile buffer for a node that has frequency >= 12 during the AM Peak Period in the model AND the TAZ must meet the landuse density threshold for suburban density) OR\n",
    "4. (a TAZ must intersect with 0.5 mile buffer for CR stops AND meet the landuse density threshold for suburban density)\n",
    "\n",
    "#### Data:\n",
    "- Heavy rail stops (points) = Blue, Orange, Red lines (including Mattapan which counts as Red)\n",
    "- Commuter Rail stops (points)\n",
    "- Light Rail stops (points) = Green and Silver lines.\n",
    "- TAZs with population and employment (polygons)\n",
    "- Bus routes with AM headway (15 minutes) \n",
    "    - NOT only MBTA\n",
    "\n",
    "### Suburban\n",
    "Basic Definition:\n",
    "0.5 mile buffer for any transit line (exclude CR , private buses)\n",
    "\n",
    "GIS Definition:\n",
    "TAZs that are not CBD, Dense Urban, or Fringe Urban AND intersect with a 0.5 mile buffer for any transit line (excluding CR and private bus lines).\n",
    "\n",
    "### Rural\n",
    "Definition of exclusion:\n",
    "All TAZs that are not CBD, Dense Urban, Fringe Urban, or Suburban."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import copy\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "#import TAZ shapefile\n",
    "\n",
    "taz = \"G:\\Regional_Modeling\\Projects\\Landuse Type_Project\\To Margrate\\TAZ_CRS.shp\"\n",
    "    #load into a geodataframe\n",
    "taz = gpd.read_file(taz)\n",
    "    #filter to just be TAZ ID and geometry\n",
    "taz = taz[['ID',\"TOT_EMP\", \"TOT_POP\",'geometry', 'AREA']]\n",
    "    #rename ID to TAZ_ID\n",
    "taz = taz.rename(columns={\"ID\":\"TAZ_ID\"})\n",
    "\n",
    "#import all transit routes\n",
    "routes = r\"G:\\Regional_Modeling\\Projects\\Landuse Type_Project\\To Margrate\\LRTP Routes_05.11.2021\\Model_Routes_CRS.shp\"\n",
    "routes = gpd.read_file(routes)\n",
    "routes = routes.query('SCEN_00 == 1') #filter to include just in current scenario\n",
    "\n",
    "#import all stops (must have line column)\n",
    "stops = r\"G:\\Regional_Modeling\\Projects\\Landuse Type_Project\\To Margrate\\LRTP Routes_05.11.2021\\Model_Stops_CRS.shp\"\n",
    "stops = gpd.read_file(stops)\n",
    "stops = stops[stops['ROUTE_ID'].isin(routes['ROUTE_ID'])] #filter to include just in current scenario (e.g. in routes)\n",
    "\n",
    "#transform TAZ and stop layers' CRS to CTPS Standard - \"EPSG:26986\" (Massachusetts State Plane)\n",
    "taz = taz.to_crs(\"EPSG:26986\")\n",
    "stops = stops.to_crs(\"EPSG:26986\")\n",
    "routes = routes.to_crs(\"EPSG:26986\")\n",
    "\n",
    "#import 5min headway and 15min headway\n",
    "f5 = r'G:\\Regional_Modeling\\Projects\\Landuse Type_Project\\Node GISDK work\\results\\Aggr_Stops_5minheadway.csv'\n",
    "f15 = r\"G:\\Regional_Modeling\\Projects\\Landuse Type_Project\\Node GISDK work\\results\\Aggr_Stops_15minheadway.csv\"\n",
    "f5 = pd.read_csv(f5, header = 0, names = ['NODE', 'FREQ5']) #data does not come with header for either csv\n",
    "f15 = pd.read_csv(f15, header = 0, names = ['NODE', 'FREQ15'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-township",
   "metadata": {},
   "source": [
    "## Filtering and Cleaning the Data\n",
    "This section is about filtering and setting up data products for use in all future sections. This means that the analysis for each section doesn't involve setting up data and data that is shared is stored in a common place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTER THE STOPS\n",
    "\n",
    "#HEAVY RAIL (CBD, DENSE URBAN, FRINGE URBAN)\n",
    "#filter all stops to just heavy rail stops (and make a copy)\n",
    "hr_stops = copy.deepcopy(stops.loc[stops['MODE'].isin([5,6,7,8])]) \n",
    "#mode 4 is Green, 5 is Red, Mattapan is 6 (Ashmont to Mattapan), Blue is 8, Orange is 7\n",
    "    #Treat Mattapan as 5 (red)\n",
    "\n",
    "hr_stops.loc[hr_stops['MODE'] == 6, 'MODE'] = 5 #this line does the same thing as above\n",
    "#filter\n",
    "hr_stops = hr_stops.loc[:,['ID', 'MODE', 'STOP_NAME', 'geometry']]\n",
    "#check\n",
    "hr_stops[hr_stops['MODE'].isin([6])] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMMUTER RAIL (DENSE URBAN, FRINGE URBAN)\n",
    "#filter all stops to just commuter rail stops (and make a copy)\n",
    "cr_stops = copy.deepcopy(stops.loc[stops['MODE'].isin([9,32,33,34,35,36,37,38,39,40])]) \n",
    "#filter\n",
    "cr_stops = cr_stops.loc[:,['ID', 'MODE', 'STOP_NAME', 'geometry']]\n",
    "cr_stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIGHT RAIL (FRINGE URBAN & CBD)\n",
    "#filter all stops to just light rail stops (and make a copy)\n",
    "lr_stops = copy.deepcopy(stops.loc[stops['MODE'].isin([4,12,13])]) \n",
    "#filter\n",
    "lr_stops = lr_stops.loc[:,['ID', 'MODE', 'STOP_NAME', 'geometry']]\n",
    "all4_lrStop = copy.deepcopy(lr_stops.loc[lr_stops['STOP_NAME'].isin(['PARK STREET GREEN', 'BOYLSTON','ARLINGTON','COPLEY SQUARE'])]) \n",
    "all4_lrStop = all4_lrStop.loc[:,['ID', 'MODE', 'STOP_NAME', 'geometry']]\n",
    "all4_lrStop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just get Nodes from Stops (DENSE URBAN, FRINGE URBAN)\n",
    "nodes = copy.deepcopy(stops.groupby('NODE').first().reset_index()) #this makes it one record per node id\n",
    "nodes = nodes[['NODE', 'geometry']]\n",
    "    #merge with the frequency data\n",
    "nodes = nodes.merge(f5, how = 'left', on = 'NODE')\n",
    "nodes = nodes.merge(f15, how = 'left', on = 'NODE')\n",
    "nodes = nodes.dropna(how = 'any', thresh=3) #make sure if both are null not using.\n",
    "nodesf5 = nodes.query('FREQ5 >= 36') #this filters so headway < 5min and only bus modes 1,2,3 (because thats whats in the file)\n",
    "nodesf15 = nodes.query('FREQ15 >= 12') #this filters so headway < 15min\n",
    "nodesf15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROUTES FOR SUBURBAN\n",
    "sub_routes = copy.deepcopy(routes.loc[routes['MODE'].isin([1,2,3,4,5,6,7,8,12,13,17,18,19,20,21,22,41,42,43])]) \n",
    "sub_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Density for TAZs\n",
    "#Density = (Population + Employment)/Area in Sq Mi\n",
    "\n",
    "taz['DensPy'] = (taz['TOT_POP']+taz['TOT_EMP'])/taz['AREA']\n",
    "\n",
    "#Flag Urban, Suburban, Rural\n",
    "taz['Den_Flag'] = np.where(taz['DensPy'] >= 10000, 1, \n",
    "                          np.where(taz['DensPy'] < 5000, 3, 2))\n",
    "taz.loc[taz['Den_Flag']<3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-cement",
   "metadata": {},
   "source": [
    "## CBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUFFER CELL\n",
    "\n",
    "#convert the 0.5 mile buffer distance into meters (CRS is in meters)\n",
    "buf5 = 0.5*1609.34\n",
    "\n",
    "#make a copy of hr_stops to buffer\n",
    "hr_buf = copy.deepcopy(hr_stops) #new used to just be hr_buf = hr_stops\n",
    "\n",
    "#Buffer the heavy rail stops\n",
    "    #keep attribute data by replacing the geometry column\n",
    "hr_buf['geometry']= hr_buf.buffer(buf5)\n",
    "\n",
    "#group by line and dissolve\n",
    "hr_buf_dis = hr_buf.dissolve(by='MODE').reset_index()\n",
    "\n",
    "#only get what we need\n",
    "hr_buf_dis = hr_buf_dis[['MODE', 'geometry']]\n",
    "hr_buf_dis.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUFFER CELL\n",
    "\n",
    "#convert the 0.25 mile buffer distance into meters (CRS is in meters)\n",
    "buf25 = 0.25*1609.34\n",
    "\n",
    "#make a copy of lr_stops to buffer\n",
    "lr4_buf = copy.deepcopy(all4_lrStop) #new used to just be hr_buf = hr_stops\n",
    "\n",
    "#Buffer the light rail stops\n",
    "lr4_buf['geometry']= lr4_buf.buffer(buf25)\n",
    "\n",
    "#group and dissolve\n",
    "lr4_buf_dis = lr4_buf.dissolve(by='MODE').reset_index()\n",
    "\n",
    "#only get what we need\n",
    "lr4_buf_dis = lr4_buf_dis[['MODE', 'geometry']].reset_index()\n",
    "lr4_buf_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-weight",
   "metadata": {},
   "source": [
    "### CBD: Intersect and Count Method TWO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INTERSECT TRY 2\n",
    "#split into individual geodataframes to intersect\n",
    "red = hr_buf_dis[hr_buf_dis['MODE'] == 5]\n",
    "blue = hr_buf_dis[hr_buf_dis['MODE'] == 7]\n",
    "orange = hr_buf_dis[hr_buf_dis['MODE'] == 8]\n",
    "\n",
    "#get all overlaps between route buffers\n",
    "rb = gpd.overlay(red, blue, how='intersection')\n",
    "ob = gpd.overlay(orange, blue, how='intersection')\n",
    "ro = gpd.overlay(red, orange, how= 'intersection')\n",
    "\n",
    "#put overlaps into one file with overlaps not overlapping (union)\n",
    "rbob = gpd.overlay(rb, ob, how='union')\n",
    "rbobro = gpd.overlay(rbob, ro, how='union',keep_geom_type=False)\n",
    "\n",
    "#add in the light rail\n",
    "rbobro = rbobro.append(lr4_buf)\n",
    "#turn ino one row multi part polygon\n",
    "rbobro['MODE'] = '578+g4'\n",
    "rbobro = rbobro.dissolve(by='MODE').reset_index()\n",
    "#get only fields we need\n",
    "rbobro = rbobro[['MODE', 'geometry']]\n",
    "rbobro\n",
    "\n",
    "taz_hr = gpd.overlay(taz, rbobro, how='intersection')\n",
    "taz_hr\n",
    "taz_hr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-distribution",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#COUNT TRY 2\n",
    "#caculate area\n",
    "#taz_hr.area\n",
    "taz_hr['area_int'] = taz_hr.area\n",
    "taz['taz_area'] = taz.area\n",
    "#join intersecting areas back to main TAZ\n",
    "taz_int = taz.merge(taz_hr, how='left', on='TAZ_ID')\n",
    "#get percent of taz that is intersecting\n",
    "taz_int['perc_hr'] = taz_int['area_int']/taz_int['taz_area']\n",
    "\n",
    "#flag TAZ's\n",
    "#flag as cbd if taz is over half covered by buffer, density is urban \n",
    "taz_int['CBD_Flag'] = np.where(((taz_int.perc_hr >0.5)&(taz_int.Den_Flag_x ==1)), 1, 0)\n",
    "\n",
    "\n",
    "#turn back into geodataframe - geometry is TAZ (not intersections of TAZ and buffers)\n",
    "taz_int = taz_int.rename(columns={'geometry_x':'geometry', 'TOT_EMP_x' : 'TOT_EMP', 'TOT_POP_x': 'TOT_POP',\n",
    "                                  'DensPy_x':'DensPy', 'Den_Flag_x': 'Den_Flag'})\n",
    "taz_int = gpd.GeoDataFrame(taz_int)\n",
    "taz_int = taz_int[['TAZ_ID', 'TOT_EMP', 'TOT_POP', 'geometry', 'DensPy', 'Den_Flag', 'CBD_Flag']]#, 'CBD_Perc']]\n",
    "\n",
    "#make sure that taz_int doesn't have duplicates because of light rail and heavy rail being dif buf polygons\n",
    "#first sort so that when deleting duplicates, deleting the ones that didn't pass CBD muster\n",
    "taz_int = taz_int.sort_values(by = ['CBD_Flag'], ascending = False)\n",
    "#delete duplicates\n",
    "taz_int = taz_int.drop_duplicates('TAZ_ID')\n",
    "\n",
    "#make testing outputs\n",
    "CBD_TAZ2 = taz_int[taz_int['CBD_Flag'] == 1]\n",
    "#CBD_TAZperc = taz_int[taz_int['CBD_Perc'] == 1]\n",
    "\n",
    "CBD_TAZ2 = CBD_TAZ2[['TAZ_ID', 'geometry', 'CBD_Flag']]\n",
    "CBD_TAZ2.plot()\n",
    "taz_int.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-roommate",
   "metadata": {},
   "source": [
    "## Dense Urban "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buffering everything for Dense Urban\n",
    "#convert the 0.5 mile buffer distance into meters (CRS is in meters)\n",
    "buf5 = 0.5*1609.34\n",
    "\n",
    "#make copies of everything to buffer\n",
    "cr_buf = copy.deepcopy(cr_stops) #new used to just be hr_buf = hr_stops\n",
    "hr_buf = copy.deepcopy(hr_stops) #replaces previous hr_buf, but idential to previous hr_buf\n",
    "nodesf5_buf = copy.deepcopy(nodesf5)\n",
    "\n",
    "#Buffer everything!!!\n",
    "cr_buf['geometry']= cr_buf.buffer(buf5)\n",
    "hr_buf['geometry']= hr_buf.buffer(buf5)\n",
    "nodesf5_buf['geometry'] = nodesf5_buf.buffer(buf5)\n",
    "\n",
    "#dissolve hr and cr and bus stops with headway < 5 min\n",
    "hr_buf_dis_du = hr_buf.dissolve().reset_index()\n",
    "cr_buf_dis = cr_buf.dissolve().reset_index()\n",
    "nodesf5_buf_dis = nodesf5_buf.dissolve().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Flag Field\n",
    "taz_du = copy.deepcopy(taz_int) #join basic taz with taz_int\n",
    "\n",
    "#(already did bus above)\n",
    "cr_list = []\n",
    "hr_list = []\n",
    "f5_list = []\n",
    "count = 0\n",
    "\n",
    "for index, row in gpd.overlay(hr_buf_dis_du, taz_du, how = 'intersection').iterrows():\n",
    "    hr_list.append(row['TAZ_ID'])\n",
    "for index, row in gpd.overlay(cr_buf_dis, taz_du, how = 'intersection').iterrows():\n",
    "    cr_list.append(row['TAZ_ID'])\n",
    "for index, row in gpd.overlay(nodesf5_buf_dis, taz_du, how = 'intersection').iterrows():\n",
    "    f5_list.append(row['TAZ_ID'])\n",
    "\n",
    "\n",
    "taz_du['DU_Flag'] = np.where(((taz_du['TAZ_ID'].isin(hr_list))) | ((taz_du['TAZ_ID'].isin(cr_list)) & (taz_du['Den_Flag'] == 1)) | ((taz_du['TAZ_ID'].isin(f5_list)) & (taz_du['Den_Flag'] == 1)), 1,0)\n",
    "taz_du.query('DU_Flag == 1') #862 records without CBD, 941 with CBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_du.query('DU_Flag == 1').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-speaking",
   "metadata": {},
   "source": [
    "## Fringe Urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buffering everything for Fringe Urban\n",
    "#convert the 0.5 and 1 mile buffer distances into meters (CRS is in meters)\n",
    "buf5 = 0.5*1609.34\n",
    "buf1 = 1*1609.34 #obvious but for clarity\n",
    "\n",
    "#make copies of everything to buffer\n",
    "cr_buf = copy.deepcopy(cr_stops) \n",
    "hr_buf1 = copy.deepcopy(hr_stops) \n",
    "nodesf15_buf = copy.deepcopy(nodesf15)\n",
    "lr_buf = copy.deepcopy(lr_stops)\n",
    "\n",
    "#Buffer everything!!!\n",
    "cr_buf['geometry']= cr_buf.buffer(buf5)\n",
    "hr_buf1['geometry']= hr_buf1.buffer(buf1) #buffer is now 1 mi\n",
    "nodesf15_buf['geometry']= nodesf15_buf.buffer(buf5)\n",
    "lr_buf['geometry']= lr_buf.buffer(buf5)\n",
    "\n",
    "#dissolve hr and cr\n",
    "hr_buf_dis_fu = hr_buf1.dissolve().reset_index()\n",
    "cr_buf_dis = cr_buf.dissolve().reset_index()\n",
    "nodesf15_buf_dis = nodesf15_buf.dissolve().reset_index()\n",
    "lr_buf_dis = lr_buf.dissolve().reset_index()\n",
    "\n",
    "lr_buf_dis.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Flag Field\n",
    "taz_fu = copy.deepcopy(taz_du) #join basic taz with taz_int\n",
    "\n",
    "cr_list = []\n",
    "hr_list = [] #1 mile now\n",
    "f15_list = []\n",
    "lr_list = []\n",
    "\n",
    "#For each row in the intersection output - take all the TAZs (will only be ones that intersect) and put in a list\n",
    "for index, row in gpd.overlay(hr_buf_dis_fu, taz_fu, how = 'intersection').iterrows():\n",
    "    hr_list.append(row['TAZ_ID'])\n",
    "for index, row in gpd.overlay(cr_buf_dis, taz_fu, how = 'intersection').iterrows():\n",
    "    cr_list.append(row['TAZ_ID'])\n",
    "for index, row in gpd.overlay(nodesf15_buf_dis, taz_fu, how = 'intersection').iterrows():\n",
    "    f15_list.append(row['TAZ_ID'])\n",
    "for index, row in gpd.overlay(lr_buf_dis, taz_fu, how = 'intersection').iterrows():\n",
    "    lr_list.append(row['TAZ_ID'])\n",
    "\n",
    "#flag if fits any of the conditions\n",
    "taz_fu['FU_Flag'] = np.where((taz_fu['TAZ_ID'].isin(hr_list)) | \n",
    "                             (taz_fu['TAZ_ID'].isin(lr_list)) |\n",
    "                             ((taz_fu['TAZ_ID'].isin(cr_list)) & (taz_fu['Den_Flag'] == 2)) | \n",
    "                             ((taz_fu['TAZ_ID'].isin(f15_list)) & (taz_fu['Den_Flag'] == 2)), 1,0)\n",
    "taz_fu.query('FU_Flag == 1') #should be 482 (no CBD or DU), 1188 with CBD and DU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-sunday",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taz_fu.query('FU_Flag == 1').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-wholesale",
   "metadata": {},
   "source": [
    "## Suburban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the buffers first\n",
    "#convert miles to meters for CRS\n",
    "buf5 = 0.5*1609.34\n",
    "#make copy to copy buffer geo into\n",
    "sub_buf = copy.deepcopy(sub_routes)\n",
    "#do the buffers\n",
    "sub_buf['geometry']= sub_buf.buffer(buf5)\n",
    "#dissolve the buffers\n",
    "sub_buf_dis = sub_buf.dissolve().reset_index()\n",
    "sub_buf_dis.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate flag field\n",
    "taz_su = copy.deepcopy(taz_fu)\n",
    "#make list of all taz that intersect with sub_buf_dis\n",
    "sub_list = []\n",
    "for index, row in gpd.overlay(sub_buf_dis, taz_su, how = 'intersection').iterrows():\n",
    "    sub_list.append(row['TAZ_ID'])\n",
    "    \n",
    "#flag everything that intersects with one of the buffers (included in list)\n",
    "taz_su['SUB_Flag'] = np.where(taz_su['TAZ_ID'].isin(sub_list), 1, 0)\n",
    "taz_su.query(\"SUB_Flag == 1\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-washington",
   "metadata": {},
   "source": [
    "## Rural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_ru = copy.deepcopy(taz_su)\n",
    "taz_ru['R_Flag'] = np.where((taz_ru['CBD_Flag'] == 0) & (taz_ru['DU_Flag'] == 0) & (taz_ru['FU_Flag'] == 0) & (taz_ru['SUB_Flag'] == 0), 1, 0)\n",
    "taz_ru.query('R_Flag == 1').plot()\n",
    "taz_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-lindsay",
   "metadata": {},
   "source": [
    "## Make Land Use Type Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_ru['LU_Type'] = np.where(taz_ru['CBD_Flag'] == 1, 1, \n",
    "                            np.where((taz_ru['CBD_Flag'] != 1) & (taz_ru['DU_Flag'] == 1), 2,\n",
    "                            np.where((taz_ru['CBD_Flag'] != 1) & (taz_ru['DU_Flag'] != 1) & (taz_ru['FU_Flag'] == 1), 3,\n",
    "                            np.where((taz_ru['CBD_Flag'] != 1) & (taz_ru['DU_Flag'] != 1) & (taz_ru['FU_Flag'] != 1) & (taz_ru['SUB_Flag'] == 1), 4, 5 \n",
    "                            ))))\n",
    "#CBD = 1, DU = 2, FU = 3, SUB = 4, Rural = 5\n",
    "taz_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9cf37d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = folium.Map()\n",
    "folium.Choropleth(taz_ru, data=taz_ru, \n",
    "                  key_on='feature.properties.TAZ_ID',\n",
    "                  columns=['TAZ_ID', 'LU_Type'], \n",
    "                  fill_color='YlGnBu').add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-hours",
   "metadata": {},
   "source": [
    "## Exports for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfp = r\"C:\\Users\\matkinson\\Downloads\\taz_ru_25.shp\"\n",
    "taz_ru.to_file(outfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-integer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ox] *",
   "language": "python",
   "name": "conda-env-ox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
